{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_selects_metadata.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTOtQ9uG-cJ_"
      },
      "source": [
        "# GENERATE METADATA FOR SELECTS\n",
        "\n",
        "Follow instructions to create a CSV file containing metadata for all videos contained in a folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv0pz3qd-sXm"
      },
      "source": [
        "## Step 1\n",
        "\n",
        "Run the cell below.\n",
        "\n",
        "You will be prompted to follow a link to authorize access to the Drive. Click the link and make sure that you sign in as ptrstoryteam@gmail.com. Copy the authorization token, return to this page, paste the token into the provided box, and hit enter on your keyboard. This completes the authorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQy4bxcE_DyU",
        "outputId": "8f9bcfc9-d496-45db-c563-9db4d2e2e4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# LIBRARIES\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# MOUNTING THE DRIVE/AUTOMATION\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfox3aitBNJu"
      },
      "source": [
        "## Step 2\n",
        "\n",
        "Run the cell below to complete initial setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ_B3M8fBLmF"
      },
      "source": [
        "# DIRECTORIES\n",
        "\n",
        "# Path to top-level folder in Footage Library\n",
        "FULL_PATH = \"/content/drive/My Drive/Protect the Results Story Team/10 PTR DISTRIBUTION/Footage Library/\"\n",
        "\n",
        "# Name of metadata folder\n",
        "METADATA_FOLDER = \"METADATA/\"\n",
        "\n",
        "# Name of selects folder\n",
        "SELECTS_FOLDER = \"selects/\"\n",
        "\n",
        "# Full path to metadata\n",
        "FULL_PATH_METADATA = FULL_PATH + METADATA_FOLDER\n",
        "\n",
        "# Full path to selects\n",
        "FULL_PATH_SELECTS = FULL_PATH + SELECTS_FOLDER\n",
        "\n",
        "# FILES\n",
        "\n",
        "# Master CSV file \n",
        "NAME_MASTER_CSV = \"master_csv_test.csv\"\n",
        "\n",
        "# List/tuple of possible file format for the videos\n",
        "LIST_VIDEO_FORMATS = (\".mov\", \".mp4\")\n",
        "\n",
        "# Name for CSV generated in outgoing folder\n",
        "NAME_GENERATED_CSV = \"metadata.csv\"\n",
        "\n",
        "# OTHER CONSTANTS\n",
        "\n",
        "# Columns of interest for the output\n",
        "COLUMN_NAMES = [\"hash_id\", \"project_id\", \"contributor_email\", \"contributor_name\",\"time_uploaded\",\n",
        "           \"shot_title\", \"caption\", \"media_type\", \"latitude\", \"longitude\", \n",
        "           \"video_duration_seconds\", \"video_duration_minutes\", \"tags\"]\n",
        "\n",
        "# Functions\n",
        "\n",
        "def metadata_from_videos_in_folder(name_folder):\n",
        "  # Keep track of hashids that have been processed\n",
        "  already_processed_hash_id = pd.read_csv(FULL_PATH_METADATA+NAME_MASTER_CSV)[\"hash_id\"].to_list()\n",
        "\n",
        "  # All filenames in target directory\n",
        "  all_filenames_in_dir = os.listdir(FULL_PATH_SELECTS + name_folder)\n",
        "\n",
        "  # All filenames of videos with specificed format(s)\n",
        "  all_video_filenames_in_dir = [f for f in all_filenames_in_dir if f.endswith(LIST_VIDEO_FORMATS)]\n",
        "\n",
        "  # The hashid of the videos\n",
        "  all_hashid_in_dir = list(map(lambda filename: filename[:-4].split(\"_\")[-1], all_video_filenames_in_dir))\n",
        "\n",
        "  # Master CSV\n",
        "  df_master_csv = pd.read_csv(FULL_PATH_METADATA+NAME_MASTER_CSV)\n",
        "\n",
        "  # List of hash_id in master csv\n",
        "  list_hashid_master = df_master_csv[\"hash_id\"].to_list()\n",
        "\n",
        "  # List of hashids from which to subset master dataframe from\n",
        "  list_hashid_subset = []\n",
        "\n",
        "  # Print the hashids that are not in master csv\n",
        "  for hashid in all_hashid_in_dir:\n",
        "    if hashid not in list_hashid_master:\n",
        "      print(hashid + \" not in the master csv\")\n",
        "    else:\n",
        "      list_hashid_subset.append(hashid)\n",
        "\n",
        "  # Subset dataframe\n",
        "  df_subset = df_master_csv[df_master_csv[\"hash_id\"].isin(list_hashid_subset)]\n",
        "\n",
        "  # Reshape final df before writing out\n",
        "  folder_name = [\"FOLDER NAME\" for num_vids in range(df_subset.shape[0])]\n",
        "  df_subset[\"folder_name\"] = folder_name\n",
        "\n",
        "  df_sorted = df_subset[[\"folder_name\", \"hash_id\", \"time_uploaded\", \"video_duration\", \"caption\", \"contributor_name\"]]\n",
        "  df_sorted.columns = [\"Folder Name\", \"Clip ID (contained within clip name\", \"Clip Date\", \"Clip Duration\", \"Caption/Location\", \"Videographer Name\"]\n",
        "\n",
        "  # Generate csv\n",
        "  df_sorted.to_csv(FULL_PATH_SELECTS+name_folder+NAME_GENERATED_CSV, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuu990MLAFOn"
      },
      "source": [
        "## Step 3\n",
        "\n",
        "Replace \n",
        "\n",
        "```\n",
        "test_selects\n",
        "```\n",
        "in the below cell with the name of the folder where your selects are stored. Be sure to preserve the quotation marks and the slash.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWHT-qkzALGY"
      },
      "source": [
        "TARGET_FOLDER = \"11.05.2020_06.00PM/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDkFtJUuBhtJ"
      },
      "source": [
        "# Step 4\n",
        "\n",
        "Run the cell below to generate the metadata CSV in the target folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD0hhTKbBmeQ",
        "outputId": "d4d351f2-ff1f-4543-9786-166f5226edf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "metadata_from_videos_in_folder(TARGET_FOLDER)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}