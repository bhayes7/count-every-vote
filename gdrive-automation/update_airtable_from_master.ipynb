{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "update_airtable_from_master.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqW3AoKsCqKd"
      },
      "source": [
        "# THIS NOTEBOOK IS A WORK IN PROGRESS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFLC92nKh5n_"
      },
      "source": [
        "# Notebook to add to Airtable from master CSV\n",
        "\n",
        "## Proposed pipeline\n",
        "Manual\n",
        "1- Export directory listing Google Sheet into csv (need to download and re-upload it)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXawACEjbw3C"
      },
      "source": [
        "## Library imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNdPN3PmJ5qY",
        "outputId": "3b33275d-ff3d-40bc-b846-e01dd5c3063d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install airtable-python-wrapper\n",
        "!pip install --upgrade gspread"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: airtable-python-wrapper in /usr/local/lib/python3.6/dist-packages (0.15.1)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.6/dist-packages (from airtable-python-wrapper) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2->airtable-python-wrapper) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2->airtable-python-wrapper) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2->airtable-python-wrapper) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2->airtable-python-wrapper) (1.24.3)\n",
            "Collecting gspread\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/ba/bc8de4f5077bd34bc873bdd67a89cb29c4f181abba8a836d2c6a0a142365/gspread-3.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
            "Installing collected packages: gspread\n",
            "  Found existing installation: gspread 3.0.1\n",
            "    Uninstalling gspread-3.0.1:\n",
            "      Successfully uninstalled gspread-3.0.1\n",
            "Successfully installed gspread-3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sonuCDB9bv3L"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "from airtable import Airtable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcXNtt7mb-JI"
      },
      "source": [
        "## Constants\n",
        "The API keys should be hidden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110cggP_d4wV"
      },
      "source": [
        "# Airtable API Key\n",
        "API_KEY = ",
        "\n",
        "# Airtable Base Key\n",
        "BASE_KEY = ",
        "\n",
        "# ProjectID to Airtable table mapping\n",
        "TABLE_MAPPING = {\n",
        "    \"stress\":\"test-table\",\n",
        "    \"bluestates\":\"bluestates\",\n",
        "    \"redstates\":\"redstates\",\n",
        "    \"bluecities\":\"bluecities\",\n",
        "    \"swingstates\":\"swingstates\"\n",
        "    } \n",
        "\n",
        "# Folder path in GDrive to CSV\n",
        "FULL_PATH_CSV = \"/content/drive/My Drive/tech-volunteering/\"\n",
        "\n",
        "# Folder path in GDrive to VIDEO\n",
        "FULL_PATH_CSV = \"/content/drive/My Drive/tech-volunteering/\"\n",
        "\n",
        "# Master CSV file \n",
        "NAME_MASTER_CSV = \"master.csv\"\n",
        "\n",
        "# File with directory listing and full_path\n",
        "NAME_DIR_LISTING_CSV = \"test-file-listing.csv\"\n",
        "\n",
        "# Columns to extract from directory listing\n",
        "DIR_LISTING_COLUMNS = [\"URL\",\"Date\"]\n",
        "\n",
        "# Columns of interest to put in Airtable\n",
        "AIRTABLE_COLUMNS = [\"hash_id\", \"contributor_email\", \"contributor_name\",\"time_uploaded\",\n",
        "           \"shot_title\", \"caption\", \"media_type\", \"latitude\", \"longitude\", \n",
        "           \"video_duration_seconds\", \"video_duration_minutes\", \"tags\", \"url_drive\", \"time_uploaded_drive\"]\n",
        "\n",
        "# List/tuple of possible file format for the videos\n",
        "LIST_VIDEO_FORMATS = (\".mov\", \".mp4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NH5TnEWds9i"
      },
      "source": [
        "## Google Collab mounting\n",
        "Need to accept token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNVhhch5dsem",
        "outputId": "d4842886-138a-4538-bedc-f4ea24ef1f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4e9QTrp2SkP"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6IG_L62SCe"
      },
      "source": [
        "def convert_to_ISO8601(raw_date):\n",
        "  try:\n",
        "    formatted_date = datetime.strptime(raw_date, \"%Y-%m-%d %H:%M:%S\").isoformat()\n",
        "  except:\n",
        "    formatted_date = datetime.strptime(raw_date, \"%m/%d/%Y %H:%M:%S\").isoformat()\n",
        "\n",
        "  return formatted_date\n",
        "\n",
        "def processed_csv_airtable(df_raw,airtable_instance):\n",
        "\n",
        "  # Record hashid that is not processed\n",
        "  error_hashid = []\n",
        "\n",
        "  # Iterate through each row\n",
        "  for i, row in df_raw.iterrows():\n",
        "    hashid = row[\"hash_id\"]\n",
        "    try: \n",
        "      # Transform into ISO 8601 formatted date\n",
        "      row[\"time_uploaded\"] = convert_to_ISO8601(row[\"time_uploaded\"])\n",
        "\n",
        "      # Split video duration into int minutes and int seconds\n",
        "      row[\"video_duration\"] = row[\"video_duration\"].split(\":\")\n",
        "      row[\"video_duration_minutes\"] = int(row[\"video_duration\"][0]) * 60 + int(row[\"video_duration\"][1])\n",
        "      row[\"video_duration_seconds\"] = int(row[\"video_duration\"][2])\n",
        "\n",
        "      # Convert latitude to float\n",
        "      row[\"latitude\"] = float(row[\"latitude\"])\n",
        "\n",
        "      # Convert longtitude to float\n",
        "      row[\"longitude\"] = float(row[\"longitude\"])\n",
        "\n",
        "      # Assuming the tags are always separated by newlines\n",
        "      row[\"tags\"] = row[\"tags\"].replace(\"\\n\", \" \") # Ensures that multiple occurences of \\n are replaced by whitespaces\n",
        "      row[\"tags\"] = row[\"tags\"].split() # Split into seperate tags\n",
        "\n",
        "      # URL in Drive\n",
        "      row[\"url_drive\"] = row[\"URL\"]\n",
        "\n",
        "      # Date uploaded\n",
        "      row[\"time_uploaded_drive\"] = convert_to_ISO8601(row[\"Date\"])\n",
        "\n",
        "      # Obtain subset to insert into Airtable\n",
        "      subset= row[AIRTABLE_COLUMNS ]\n",
        "\n",
        "      dict_subset = subset.to_dict()\n",
        "\n",
        "      airtable_instance.insert(dict_subset, typecast=True)\n",
        "\n",
        "    except Exception as e:\n",
        "          print(\"\\n\")\n",
        "          print(str(e))\n",
        "          print(\"Unable to process: \" + hashid)\n",
        "          error_hashid.append((hashid, str(e)))\n",
        "          continue\n",
        "  return error_hashid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47PcnBdAkaS4"
      },
      "source": [
        "## CSV processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVLYhqBD7kFI"
      },
      "source": [
        "# From which row to start adding from master csv\n",
        "starting_row = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3uNjk1gruva",
        "outputId": "1f46098e-bbda-4f60-b801-7f51be4604ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# From which row to start adding from master csv\n",
        "starting_row = 0\n",
        "\n",
        "# Read CSV of directory listing\n",
        "df_dir_list = pd.read_csv(FULL_PATH_CSV + NAME_DIR_LISTING_CSV)\n",
        "\n",
        "# Only subset the video files \n",
        "df_dir_list_subset = df_dir_list[df_dir_list[\"Name\"].str.endswith(LIST_VIDEO_FORMATS)]\n",
        "\n",
        "# Add column for hashIDs\n",
        "df_dir_list_subset[\"hash_id\"] =  df_dir_list_subset['Name'].apply(lambda filename: filename[:-4].split(\"_\")[-1])\n",
        "\n",
        "# Make it ready to merge with master csv via hash_id\n",
        "df_dir_list_subset_for_merge = df_dir_list_subset[DIR_LISTING_COLUMNS + [\"hash_id\"]]\n",
        "\n",
        "# Read master csv\n",
        "df_master_csv = pd.read_csv(FULL_PATH_CSV+NAME_MASTER_CSV,skiprows=starting_row )\n",
        "\n",
        "# Merge\n",
        "df_merged = df_master_csv.merge(df_dir_list_subset_for_merge, how=\"left\", on=\"hash_id\")\n",
        "\n",
        "# Unique project id's\n",
        "list_unique_project_id = list(df_merged[\"project_id\"].unique())\n",
        "\n",
        "# For each project id\n",
        "for project_id in list_unique_project_id:\n",
        "  df_merged_subset = df_merged[df_merged[\"project_id\"] == project_id]\n",
        "  table_name = TABLE_MAPPING[project_id]\n",
        "  # Authentificate in Airtable\n",
        "  try:\n",
        "    airtable_instance_project = Airtable(BASE_KEY, table_name, api_key=API_KEY)\n",
        "    print(\"\\n Airtable authenticated \\n\")\n",
        "  except:\n",
        "      print(\"Problem with Airtable authentication\")\n",
        "\n",
        "  print(\"Adding to table \" + table_name + \"\\n\")\n",
        "  # Add to Airtable\n",
        "  list_errors = processed_csv_airtable(df_merged_subset,airtable_instance_project)\n",
        "\n",
        "  # What to do with list of errors?\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Airtable authenticated \n",
            "\n",
            "Adding to table test-table\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjj0523PQeHU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWha-ZihxuAJ"
      },
      "source": [
        "# Update Airtable and Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K456m1LkxxsO"
      },
      "source": [
        "## Step 1\n",
        "\n",
        "Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiyGW1y_6u-R"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwpu4svex1ER",
        "outputId": "3891356c-1554-44ec-a083-ac86d1464290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "from airtable import Airtable\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxx498Gyx64Q"
      },
      "source": [
        "## Step 2\n",
        "\n",
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4mfIKzjx6uL"
      },
      "source": [
        "# AIRTABLE SETUP\n",
        "\n",
        "# Airtable API Key\n",
        "API_KEY = ",
        "\n",
        "# Airtable Base Key\n",
        "BASE_KEY = ",
        "\n",
        "# ProjectID to Airtable table mapping\n",
        "TABLE_MAPPING = {\n",
        "    \"stress\":\"test-table\",\n",
        "    \"bluestates\":\"bluestates\",\n",
        "    \"redstates\":\"redstates\",\n",
        "    \"bluecities\":\"bluecities\",\n",
        "    \"swingstates\":\"swingstates\"\n",
        "    } \n",
        "\n",
        "# PATHS\n",
        "\n",
        "# Folder path in GDrive to videos\n",
        "FULL_PATH_VIDEO = \"/content/drive/My Drive/Protect the Results Story Team/10 PTR DISTRIBUTION/Footage Library/\"\n",
        "\n",
        "# Folder path in GDrive to CSV\n",
        "FULL_PATH_CSV = \"/content/drive/My Drive/Protect the Results Story Team/10 PTR DISTRIBUTION/Footage Library/METADATA/\"\n",
        "\n",
        "# FILES\n",
        "\n",
        "# Master CSV file \n",
        "NAME_MASTER_CSV = \"master_csv_test.csv\"\n",
        "\n",
        "# File with directory listing and full_path\n",
        "NAME_DIR_LISTING_CSV = \"video_directory.csv\"\n",
        "\n",
        "# OTHER CONSTANTS\n",
        "\n",
        "# Columns to extract from directory listing\n",
        "DIR_LISTING_COLUMNS = [\"URL\",\"Date\"]\n",
        "\n",
        "# Columns of interest to put in Airtable\n",
        "AIRTABLE_COLUMNS = [\"hash_id\", \"contributor_email\", \"contributor_name\",\"time_uploaded\",\n",
        "           \"shot_title\", \"caption\", \"media_type\", \"latitude\", \"longitude\", \n",
        "           \"video_duration_seconds\", \"video_duration_minutes\", \"tags\", \"url_drive\", \"time_uploaded_drive\"]\n",
        "\n",
        "# List/tuple of possible file format for the videos\n",
        "LIST_VIDEO_FORMATS = (\".mov\", \".mp4\")\n",
        "\n",
        "# FUNCTIONS\n",
        "\n",
        "def convert_to_ISO8601(raw_date):\n",
        "  try:\n",
        "    formatted_date = datetime.strptime(raw_date, \"%Y-%m-%d %H:%M:%S\").isoformat()\n",
        "  except:\n",
        "    formatted_date = datetime.strptime(raw_date, \"%m/%d/%Y %H:%M:%S\").isoformat()\n",
        "\n",
        "  return formatted_date\n",
        "\n",
        "def processed_csv_airtable(df_raw,airtable_instance):\n",
        "\n",
        "  # Record hashid that is not processed\n",
        "  error_hashid = []\n",
        "\n",
        "  # Iterate through each row\n",
        "  for i, row in df_raw.iterrows():\n",
        "    hashid = row[\"hash_id\"]\n",
        "    try: \n",
        "      # Transform into ISO 8601 formatted date\n",
        "      row[\"time_uploaded\"] = convert_to_ISO8601(row[\"time_uploaded\"])\n",
        "\n",
        "      # Split video duration into int minutes and int seconds\n",
        "      row[\"video_duration\"] = row[\"video_duration\"].split(\":\")\n",
        "      row[\"video_duration_minutes\"] = int(row[\"video_duration\"][0]) * 60 + int(row[\"video_duration\"][1])\n",
        "      row[\"video_duration_seconds\"] = int(row[\"video_duration\"][2])\n",
        "\n",
        "      # Convert latitude to float\n",
        "      row[\"latitude\"] = float(row[\"latitude\"])\n",
        "\n",
        "      # Convert longtitude to float\n",
        "      row[\"longitude\"] = float(row[\"longitude\"])\n",
        "\n",
        "      # Assuming the tags are always separated by newlines\n",
        "      row[\"tags\"] = row[\"tags\"].replace(\"\\n\", \" \") # Ensures that multiple occurences of \\n are replaced by whitespaces\n",
        "      row[\"tags\"] = row[\"tags\"].split() # Split into seperate tags\n",
        "\n",
        "      # URL in Drive\n",
        "      row[\"url_drive\"] = row[\"URL\"]\n",
        "\n",
        "      # Date uploaded\n",
        "      row[\"time_uploaded_drive\"] = convert_to_ISO8601(row[\"Date\"])\n",
        "\n",
        "      # Obtain subset to insert into Airtable\n",
        "      subset= row[AIRTABLE_COLUMNS ]\n",
        "\n",
        "      dict_subset = subset.to_dict()\n",
        "\n",
        "      airtable_instance.insert(dict_subset, typecast=True)\n",
        "\n",
        "    except Exception as e:\n",
        "          print(\"\\n\")\n",
        "          print(str(e))\n",
        "          print(\"Unable to process: \" + hashid)\n",
        "          error_hashid.append((hashid, str(e)))\n",
        "          continue\n",
        "  return error_hashid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bouvlfpm7Bt1"
      },
      "source": [
        "# read in the existing google sheet directory as a pandas dataframe\n",
        "directory = gc.open(\"project_directory\").sheet1\n",
        "\n",
        "rows = directory.get_all_values()\n",
        "\n",
        "import pandas as pd\n",
        "df_dir_list = pd.DataFrame.from_records(rows)\n",
        "\n",
        "# need to replace column names with first row\n",
        "new_header = df_dir_list.iloc[0] \n",
        "df_dir_list = df_dir_list[1:] \n",
        "df_dir_list.columns = new_header "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR1T0FI19faS",
        "outputId": "69dc57cb-7a54-46c6-fc3f-85288e478848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "source": [
        "df_dir_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full Path</th>\n",
              "      <th>Name</th>\n",
              "      <th>Date</th>\n",
              "      <th>URL</th>\n",
              "      <th>Last Updated</th>\n",
              "      <th>Description</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Footage Library/selects</td>\n",
              "      <td>selects</td>\n",
              "      <td>11/4/2020 12:21:48</td>\n",
              "      <td>https://drive.google.com/drive/folders/1w62_GR...</td>\n",
              "      <td>11/4/2020 12:21:42</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Footage Library/METADATA</td>\n",
              "      <td>METADATA</td>\n",
              "      <td>11/4/2020 12:21:46</td>\n",
              "      <td>https://drive.google.com/drive/folders/1gXaNnx...</td>\n",
              "      <td>11/4/2020 12:21:38</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Footage Library/METADATA/processed_logs</td>\n",
              "      <td>processed_logs</td>\n",
              "      <td>11/4/2020 12:22:53</td>\n",
              "      <td>https://drive.google.com/drive/folders/1xAkEl9...</td>\n",
              "      <td>11/4/2020 12:22:46</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Footage Library/METADATA/processed_csv</td>\n",
              "      <td>processed_csv</td>\n",
              "      <td>11/4/2020 12:22:50</td>\n",
              "      <td>https://drive.google.com/drive/folders/1806TYd...</td>\n",
              "      <td>11/4/2020 12:22:42</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Footage Library/METADATA/incoming_csv</td>\n",
              "      <td>incoming_csv</td>\n",
              "      <td>11/4/2020 12:22:45</td>\n",
              "      <td>https://drive.google.com/drive/folders/1S-ogqd...</td>\n",
              "      <td>11/4/2020 12:22:38</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>Footage Library/swingstates/trim/swingstates_C...</td>\n",
              "      <td>swingstates_Cindy.burstein@gmail.com_201104_NO...</td>\n",
              "      <td>11/4/2020 13:21:51</td>\n",
              "      <td>https://drive.google.com/file/d/1ZPtaVPgJDBueh...</td>\n",
              "      <td>11/4/2020 21:09:36</td>\n",
              "      <td></td>\n",
              "      <td>14618645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>Footage Library/swingstates/trim/swingstates_H...</td>\n",
              "      <td>swingstates_Hillary_201104_mqZqGAQWXfm5.mov</td>\n",
              "      <td>11/4/2020 13:01:44</td>\n",
              "      <td>https://drive.google.com/file/d/1O0YWqiensqxO9...</td>\n",
              "      <td>11/4/2020 20:55:12</td>\n",
              "      <td></td>\n",
              "      <td>64602037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>Footage Library/swingstates/trim/swingstates_C...</td>\n",
              "      <td>swingstates_Cindy.burstein@gmail.com_201104_lR...</td>\n",
              "      <td>11/4/2020 13:02:25</td>\n",
              "      <td>https://drive.google.com/file/d/18PnCasDrS7QX9...</td>\n",
              "      <td>11/4/2020 13:28:53</td>\n",
              "      <td></td>\n",
              "      <td>16298093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>Footage Library/swingstates/sensitive</td>\n",
              "      <td>sensitive</td>\n",
              "      <td>11/3/2020 10:27:40</td>\n",
              "      <td>https://drive.google.com/drive/folders/1nS9b1A...</td>\n",
              "      <td>11/3/2020 9:39:56</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>Footage Library/swingstates/sensitive/swingsta...</td>\n",
              "      <td>swingstates_Justin_201104_vQ2QLD7O8FA3.mp4</td>\n",
              "      <td>11/4/2020 15:34:22</td>\n",
              "      <td>https://drive.google.com/file/d/1J5SGf2ePDNrCi...</td>\n",
              "      <td>11/4/2020 23:15:48</td>\n",
              "      <td></td>\n",
              "      <td>31407723</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>419 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "0                                            Full Path  ...      Size\n",
              "1                              Footage Library/selects  ...         0\n",
              "2                             Footage Library/METADATA  ...         0\n",
              "3              Footage Library/METADATA/processed_logs  ...         0\n",
              "4               Footage Library/METADATA/processed_csv  ...         0\n",
              "5                Footage Library/METADATA/incoming_csv  ...         0\n",
              "..                                                 ...  ...       ...\n",
              "415  Footage Library/swingstates/trim/swingstates_C...  ...  14618645\n",
              "416  Footage Library/swingstates/trim/swingstates_H...  ...  64602037\n",
              "417  Footage Library/swingstates/trim/swingstates_C...  ...  16298093\n",
              "418              Footage Library/swingstates/sensitive  ...         0\n",
              "419  Footage Library/swingstates/sensitive/swingsta...  ...  31407723\n",
              "\n",
              "[419 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQcakVa_zCAK"
      },
      "source": [
        "## Step 3\n",
        "\n",
        "Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5_71vGuzEj0",
        "outputId": "ad512fff-2798-43a9-8710-d9f3d8dfc00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# From which row to start adding from master csv\n",
        "starting_row = 0\n",
        "\n",
        "# Only subset the video files \n",
        "df_dir_list_subset = df_dir_list[df_dir_list[\"Name\"].str.endswith(LIST_VIDEO_FORMATS)]\n",
        "\n",
        "# Export directory of videos\n",
        "df_dir_list_subset.to_csv(FULL_PATH_VIDEO + NAME_DIR_LISTING_CSV)\n",
        "\n",
        "# Add column for hashIDs\n",
        "df_dir_list_subset[\"hash_id\"] =  df_dir_list_subset['Name'].apply(lambda filename: filename[:-4].split(\"_\")[-1])\n",
        "\n",
        "# Make it ready to merge with master csv via hash_id\n",
        "df_dir_list_subset_for_merge = df_dir_list_subset[DIR_LISTING_COLUMNS + [\"hash_id\"]]\n",
        "\n",
        "# Read master csv\n",
        "df_master_csv = pd.read_csv(FULL_PATH_CSV+NAME_MASTER_CSV,skiprows=starting_row )\n",
        "\n",
        "# Merge\n",
        "df_merged = df_master_csv.merge(df_dir_list_subset_for_merge, how=\"left\", on=\"hash_id\")\n",
        "\n",
        "# Unique project id's\n",
        "list_unique_project_id = list(df_merged[\"project_id\"].unique())\n",
        "\n",
        "# For each project id\n",
        "for project_id in list_unique_project_id:\n",
        "  df_merged_subset = df_merged[df_merged[\"project_id\"] == project_id]\n",
        "  table_name = TABLE_MAPPING[project_id]\n",
        "  # Authentificate in Airtable\n",
        "  try:\n",
        "    airtable_instance_project = Airtable(BASE_KEY, table_name, api_key=API_KEY)\n",
        "    print(\"\\n Airtable authenticated \\n\")\n",
        "  except:\n",
        "      print(\"Problem with Airtable authentication\")\n",
        "\n",
        "  print(\"Adding to table \" + table_name + \"\\n\")\n",
        "  # Add to Airtable\n",
        "  list_errors = processed_csv_airtable(df_merged_subset,airtable_instance_project)\n",
        "\n",
        "  # What to do with list of errors?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Airtable authenticated \n",
            "\n",
            "Adding to table bluestates\n",
            "\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: LZ9ZWOwP0t4N\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: BrBr97xq3U38\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: OgYg6XGr4Fvo\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: XQDQkx5nghqL\n",
            "\n",
            " Airtable authenticated \n",
            "\n",
            "Adding to table swingstates\n",
            "\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: NOkOXl06WF9M\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: 08R8ExLzZhJY\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: Y7E7rLxD5fOG\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: mqZq84n33fZq\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: 16w6EPxGju7K\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: r2k2BnzQWS2V\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: Y7E7rn5pGhOW\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: Y7E7rn5pGhOW\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: z6p6QNKpqI35\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: r2k2BqOJpSVO\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: lRYRMAWLAUAD\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: jYRYOpwJxT1G\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: J868W78OphVB\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: OgYg6Z2nKC46\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: r2k2VRk3Yh1w\n",
            "\n",
            "\n",
            "invalid literal for int() with base 10: 'video'\n",
            "Unable to process: pZYZB3nj7FjZ\n",
            "\n",
            "\n",
            "invalid literal for int() with base 10: 'video'\n",
            "Unable to process: pZYZB3nj7FjZ\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: gpJp8R93oTwA\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: XQDQVpPEBHx6\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: z6p6lYAGyuNA\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: x6k6LPPGQCOL\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: pZYZLDx7NixJ\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: 16w63QMBWT5m\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: 7939VWvQPuOp\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: vQ2QLxMjPSKO\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: vQ2QLD7O8FA3\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: jYRY6nGn4HPx\n",
            "\n",
            "\n",
            "('404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates', \"404 Client Error: Not Found for url: https://api.airtable.com/v0/appNVrKGAEP2sHXUw/swingstates [Error: {'type': 'TABLE_NOT_FOUND', 'message': 'Could not find table swingstates in application appNVrKGAEP2sHXUw'}]\")\n",
            "Unable to process: z6p6YXNX3cEN\n",
            "\n",
            "\n",
            "invalid literal for int() with base 10: 'video'\n",
            "Unable to process: pZYZB3nj7FjZ\n",
            "\n",
            "\n",
            "invalid literal for int() with base 10: 'video'\n",
            "Unable to process: pZYZB3nj7FjZ\n",
            "\n",
            " Airtable authenticated \n",
            "\n",
            "Adding to table bluecities\n",
            "\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: K8r890x0NCMO\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: BrBr9YkX8C0D\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: nR5R6JmmgugA\n",
            "\n",
            "\n",
            "strptime() argument 1 must be str, not float\n",
            "Unable to process: 28k8O25Oou0W\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
